{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc16bbd",
   "metadata": {},
   "source": [
    "# Azure DocumentDB Customer 360 App Simulation\n",
    "\n",
    "This notebook demonstrates how to build a modern, intelligent customer data platform using Azure DocumentDB.\n",
    "\n",
    "## Objectives\n",
    "- Provision DocumentDB database and collections required.\n",
    "- Generate hundreds of customers with their bank and credit card transactions data.\n",
    "- Use various Aggregation pipelines \n",
    "- Incorporate Graph lookups\n",
    "- Power BI style dashboards for real-time insights\n",
    "- Vector Embeddings + Retrieval-Augmented Generation (RAG) with Azure OpenAI\n",
    "\n",
    "## Prerequisites\n",
    "- Azure DocumentDB cluster setup.\n",
    "- Python 3.9+ environment with Jupyter Notebook.\n",
    "- Azure DocumentDB connection string, Open AI endpoint and key.\n",
    "- Ensure proper permissions to write input files under the data folder, and create a .env file for the credentials required.\n",
    "- Please refer to this link to create python environments in VS Code, [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46945d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import quote_plus\n",
    "import networkx as nx\n",
    "\n",
    "env_name = \"./config/config.env\" # using config.env template, change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "connection_string = config['DOCUMENTDB_CONN_STRING']\n",
    "cust_file_path = \"./data/customers.csv\"\n",
    "bank_trans_file_path = \"./data/customer_bank_transactions.csv\"\n",
    "cc_trans_file_path = \"./data/customer_credit_card_transactions.csv\"\n",
    "db_name = \"customer360\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd900d45",
   "metadata": {},
   "source": [
    "## Generate Sample Customer 360 Data with Bank and Credit Card Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ca2ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def format_elapsed_time(elapsed_seconds):\n",
    "    hours, remainder = divmod(elapsed_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{seconds:05.2f}\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Generate synthetic customer profiles\n",
    "def generate_customers(num_customers):\n",
    "    customers = []\n",
    "    for i in range(num_customers):\n",
    "        customer_id = f\"C{1000 + i}\"\n",
    "        customers.append({\n",
    "            \"customer_id\": customer_id,\n",
    "            \"name\": fake.name(),\n",
    "            \"email\": fake.email(),\n",
    "            \"phone\": fake.phone_number(),\n",
    "            \"address\": fake.address().replace(\"\\n\", \", \"),\n",
    "            \"dob\": fake.date_of_birth(minimum_age=18, maximum_age=80).strftime(\"%Y-%m-%d\"),\n",
    "            \"account_open_date\": fake.date_between(start_date='-10y', end_date='today').strftime(\"%Y-%m-%d\")\n",
    "        })\n",
    "    return customers\n",
    "\n",
    "# Generate synthetic bank transactions\n",
    "def generate_bank_transactions(customers, num_transactions):\n",
    "    transactions = []\n",
    "    transaction_types = [\"deposit\", \"withdrawal\", \"transfer\"]\n",
    "    for i in range(num_transactions):\n",
    "        customer = random.choice(customers)\n",
    "        transactions.append({\n",
    "            \"transaction_id\": f\"B{10000 + i}\",\n",
    "            \"customer_id\": customer[\"customer_id\"],\n",
    "            \"date\": fake.date_between(start_date='-2y', end_date='today').strftime(\"%Y-%m-%d\"),\n",
    "            \"type\": random.choice(transaction_types),\n",
    "            \"amount\": round(random.uniform(50, 5000), 2),\n",
    "            \"description\": fake.sentence()\n",
    "        })\n",
    "    return transactions\n",
    "\n",
    "# Generate synthetic credit card transactions\n",
    "def generate_credit_card_transactions(customers, num_transactions):\n",
    "    transactions = []\n",
    "    categories = [\"groceries\", \"travel\", \"electronics\", \"restaurants\", \"clothing\", \"utilities\"]\n",
    "    for i in range(num_transactions):\n",
    "        customer = random.choice(customers)\n",
    "        transactions.append({\n",
    "            \"transaction_id\": f\"CC{20000 + i}\",\n",
    "            \"customer_id\": customer[\"customer_id\"],\n",
    "            \"date\": fake.date_between(start_date='-2y', end_date='today').strftime(\"%Y-%m-%d\"),\n",
    "            \"merchant\": fake.company(),\n",
    "            \"category\": random.choice(categories),\n",
    "            \"amount\": round(random.uniform(10, 2000), 2),\n",
    "            \"description\": fake.sentence()\n",
    "        })\n",
    "    return transactions\n",
    "\n",
    "# Generate and save datasets\n",
    "num_customers = 100\n",
    "num_bank_transactions = 500\n",
    "num_credit_card_transactions = 500\n",
    "\n",
    "customers = generate_customers(num_customers)\n",
    "bank_transactions = generate_bank_transactions(customers, num_bank_transactions)\n",
    "credit_card_transactions = generate_credit_card_transactions(customers, num_credit_card_transactions)\n",
    "\n",
    "# Ensure the directory exists if not create it\n",
    "os.makedirs(os.path.dirname(cust_file_path), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.dirname(bank_trans_file_path), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.dirname(cc_trans_file_path), exist_ok=True)\n",
    "\n",
    "pd.DataFrame(customers).to_csv(cust_file_path, index=False)\n",
    "pd.DataFrame(bank_transactions).to_csv(bank_trans_file_path, index=False)\n",
    "pd.DataFrame(credit_card_transactions).to_csv(cc_trans_file_path, index=False)\n",
    "\n",
    "print(\"Synthetic datasets saved as CSV files.\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Generated customer transactions and saved to {cust_file_path, bank_trans_file_path, cc_trans_file_path}\")\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time_str = format_elapsed_time(elapsed_time.total_seconds())\n",
    "print(f\"Total time taken to generate the input file HH:MM:SS: {elapsed_time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c12eb",
   "metadata": {},
   "source": [
    "## Ingest Data into Azure DocumentDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29736880",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with your Azure DocumentDB connection string\n",
    "client = MongoClient(connection_string)\n",
    "client.drop_database(db_name) #drop if DB exists and recreate\n",
    "db = client[db_name]\n",
    "\n",
    "# Load CSVs\n",
    "customers_df = pd.read_csv(cust_file_path)\n",
    "bank_tx_df = pd.read_csv(bank_trans_file_path)\n",
    "cc_tx_df = pd.read_csv(cc_trans_file_path)\n",
    "\n",
    "start_time = datetime.now()\n",
    "# Insert into DocumentDB, provide the respective collection names\n",
    "db.customers.insert_many(customers_df.to_dict(orient=\"records\"))\n",
    "db.customer_bank_trans.insert_many(bank_tx_df.to_dict(orient=\"records\"))\n",
    "db.customer_card_trans.insert_many(cc_tx_df.to_dict(orient=\"records\"))\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time_str = format_elapsed_time(elapsed_time.total_seconds())\n",
    "print(f\"Total time taken to insert the input files to DocumentDB collections, HH:MM:SS: {elapsed_time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797c2a0",
   "metadata": {},
   "source": [
    "## Build various aggregation query pipelines\n",
    "### # 1. Customers with accounts older than 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7ea95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "now = datetime.now(UTC)\n",
    "\n",
    "# 1. Customers with accounts older than 5 years\n",
    "print(\"\\n1. Customers with accounts older than 5 years:\")\n",
    "result1 = db.customers.aggregate([\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"account_open_date_dt\": {\n",
    "                \"$cond\": {\n",
    "                    \"if\": { \"$eq\": [{ \"$type\": \"$account_open_date\" }, \"string\"] },\n",
    "                    \"then\": { \"$dateFromString\": { \"dateString\": \"$account_open_date\" } },\n",
    "                    \"else\": \"$account_open_date\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"account_age\": {\n",
    "                \"$divide\": [\n",
    "                    { \"$subtract\": [now, \"$account_open_date_dt\"] },\n",
    "                    1000 * 60 * 60 * 24 * 365  # Convert milliseconds to years\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"account_age\": { \"$gt\": 5 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"account_age\": -1 }\n",
    "    },\n",
    "    {\n",
    "        \"$limit\": 5\n",
    "    }\n",
    "])\n",
    "pprint(list(result1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d9123",
   "metadata": {},
   "source": [
    "### 2. Credit card transactions over $300 in groceries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927fd67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Credit card transactions over $300 in groceries\n",
    "print(\"\\n2. Credit card transactions over $300 in groceries:\")\n",
    "result2 = db.customer_card_trans.aggregate([\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"amount\": { \"$gt\": 300 },\n",
    "            \"category\": \"groceries\"\n",
    "        }\n",
    "    }, { \"$limit\": 5 }\n",
    "\n",
    "])\n",
    "pprint(list(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3011c",
   "metadata": {},
   "source": [
    "### 3. Bank withdrawals over $200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbaa681",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Bank withdrawals over $200\n",
    "print(\"\\n3. Bank withdrawals over $200:\")\n",
    "result3 = db.customer_bank_trans.aggregate([\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"type\": \"withdrawal\",\n",
    "            \"amount\": { \"$gt\": 200 }\n",
    "        }\n",
    "    }, { \"$limit\": 5 }\n",
    "])\n",
    "pprint(list(result3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e5158",
   "metadata": {},
   "source": [
    "### 4. Group transactions by customer and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be764f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Group transactions by customer and count\n",
    "print(\"\\n4. Group transactions by customer and count:\")\n",
    "result4 = db.customer_bank_trans.aggregate([\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$customer_id\",\n",
    "            \"total_transactions\": { \"$sum\": 1 },\n",
    "            \"total_amount\": { \"$sum\": \"$amount\" }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"total_amount\": -1 }\n",
    "    }, { \"$limit\": 5 }\n",
    "])\n",
    "pprint(list(result4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff0738",
   "metadata": {},
   "source": [
    "### 5. Monthly spending summary for credit cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a5afa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Monthly spending summary for credit cards\n",
    "print(\"\\n5. Monthly spending summary for credit cards:\")\n",
    "result5 = db.customer_card_trans.aggregate([\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"month\": { \"$month\": { \"$dateFromString\": { \"dateString\": \"$date\" } } },\n",
    "            \"year\": { \"$year\": { \"$dateFromString\": { \"dateString\": \"$date\" } } }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": { \"year\": \"$year\", \"month\": \"$month\" },\n",
    "            \"total_spent\": { \"$sum\": \"$amount\" },\n",
    "            \"transaction_count\": { \"$sum\": 1 }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": { \"_id.year\": -1, \"_id.month\": -1 }\n",
    "    }\n",
    "    , \n",
    "    { \"$limit\": 5 }\n",
    "])\n",
    "pprint(list(result5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1e308",
   "metadata": {},
   "source": [
    "### 6. Join customers with their transactions using $lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710249a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Join customers with their transactions using $lookup\n",
    "print(\"\\n6. Join customers with their transactions using $lookup:\")\n",
    "result6 = db.customers.aggregate([\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"bank_transactions\",\n",
    "            \"localField\": \"customer_id\",\n",
    "            \"foreignField\": \"customer_id\",\n",
    "            \"as\": \"bank_txns\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"credit_card_transactions\",\n",
    "            \"localField\": \"customer_id\",\n",
    "            \"foreignField\": \"customer_id\",\n",
    "            \"as\": \"credit_txns\"\n",
    "        }\n",
    "    }\n",
    "    , { \"$limit\": 5 }\n",
    "])\n",
    "pprint(list(result6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743bfba",
   "metadata": {},
   "source": [
    "## Use $graphLookup feature traversal for Credit Card and Bank Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2093c32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the sample customer_id\n",
    "sample_customer_id = \"C1001\"  # Replace with a valid customer_id from your dataset\n",
    "\n",
    "# Graph lookup pipeline to retrieve both credit card and bank transactions\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\"customer_id\": sample_customer_id}\n",
    "    },\n",
    "    {\n",
    "        \"$graphLookup\": {\n",
    "            \"from\": \"customer_card_trans\",\n",
    "            \"startWith\": \"$customer_id\",\n",
    "            \"connectFromField\": \"customer_id\",\n",
    "            \"connectToField\": \"customer_id\",\n",
    "            \"as\": \"related_credit_card_transactions\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$graphLookup\": {\n",
    "            \"from\": \"customer_bank_trans\",\n",
    "            \"startWith\": \"$customer_id\",\n",
    "            \"connectFromField\": \"customer_id\",\n",
    "            \"connectToField\": \"customer_id\",\n",
    "            \"as\": \"related_bank_transactions\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"customer_id\": 1,\n",
    "            \"name\": 1,\n",
    "            \"related_credit_card_transactions\": 1,\n",
    "            \"related_bank_transactions\": 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute the aggregation\n",
    "graph_result = list(db.customers.aggregate(pipeline))\n",
    "\n",
    "# Print results\n",
    "if graph_result:\n",
    "    print(f\"üîç Related credit card transactions for customer {sample_customer_id}:\")\n",
    "    for txn in graph_result[0][\"related_credit_card_transactions\"]:\n",
    "        print(txn)\n",
    "\n",
    "    print(f\"\\nüè¶ Related bank transactions for customer {sample_customer_id}:\")\n",
    "    for txn in graph_result[0][\"related_bank_transactions\"]:\n",
    "        print(txn)\n",
    "else:\n",
    "    print(f\"‚ùå No customer found with ID {sample_customer_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3143b5a",
   "metadata": {},
   "source": [
    "## Graph Visualization using Python libraries, similar approach can be used on other Graph Visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c1682",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# print(graph_result)\n",
    "customer_data = graph_result[0]\n",
    "\n",
    "# Add customer node\n",
    "customer_id = customer_data[\"customer_id\"]\n",
    "customer_name = customer_data[\"name\"]\n",
    "G.add_node(customer_id, label=customer_name, type=\"customer\")\n",
    "\n",
    "# Add credit card transaction nodes and edges\n",
    "for tx in customer_data[\"related_credit_card_transactions\"]:\n",
    "    tx_id = tx[\"transaction_id\"]\n",
    "    tx_label = f\"Card: {tx['category']} ${tx['amount']}\"\n",
    "    G.add_node(tx_id, label=tx_label, type=\"credit_card_tx\")\n",
    "    G.add_edge(customer_id, tx_id)\n",
    "\n",
    "# Add bank transaction nodes and edges\n",
    "for tx in customer_data[\"related_bank_transactions\"]:\n",
    "    tx_id = tx[\"transaction_id\"]\n",
    "    tx_label = f\"Bank: {tx['type']} ${tx['amount']}\"\n",
    "    G.add_node(tx_id, label=tx_label, type=\"bank_tx\")\n",
    "    G.add_edge(customer_id, tx_id)\n",
    "\n",
    "# Draw graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Assign colors based on node type\n",
    "node_colors = []\n",
    "for node, data in G.nodes(data=True):\n",
    "    if data[\"type\"] == \"customer\":\n",
    "        node_colors.append(\"skyblue\")\n",
    "    elif data[\"type\"] == \"bank_tx\":\n",
    "        node_colors.append(\"lightgreen\")\n",
    "    else:\n",
    "        node_colors.append(\"salmon\")\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=600)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "\n",
    "# Draw labels\n",
    "labels = {node: data[\"label\"] for node, data in G.nodes(data=True)}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=9)\n",
    "\n",
    "plt.title(\"Customer Transaction Graph\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f12dd",
   "metadata": {},
   "source": [
    "## Graph Visualization of Customer Transactions\n",
    "### Customers ‚Üí Transactions ‚Üí Merchants\n",
    "### Customers ‚Üí Transactions ‚Üí Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f073f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# print(graph_result)\n",
    "customer_data = graph_result[0]\n",
    "\n",
    "# Add customer node\n",
    "customer_id = customer_data[\"customer_id\"]\n",
    "G.add_node(customer_id, label=customer_data[\"name\"], type=\"customer\")\n",
    "\n",
    "# Add credit card transactions and merchant/category/offer nodes\n",
    "for tx in customer_data[\"related_credit_card_transactions\"]:\n",
    "    tx_id = tx[\"transaction_id\"]\n",
    "    tx_label = f\"Card: {tx['category']} ${tx['amount']}\"\n",
    "    merchant = tx[\"merchant\"]\n",
    "    category = tx[\"category\"]\n",
    "    # offer = customer_data[\"offers\"].get(category, \"No offer\")\n",
    "\n",
    "    # Transaction node\n",
    "    G.add_node(tx_id, label=tx_label, type=\"credit_card_tx\")\n",
    "    G.add_edge(customer_id, tx_id)\n",
    "\n",
    "    # Merchant node\n",
    "    G.add_node(merchant, label=merchant, type=\"merchant\")\n",
    "    G.add_edge(tx_id, merchant)\n",
    "\n",
    "    # Category node\n",
    "    G.add_node(category, label=category, type=\"category\")\n",
    "    G.add_edge(tx_id, category)\n",
    "\n",
    "    # Offer node\n",
    "    # G.add_node(offer, label=offer, type=\"offer\")\n",
    "    # G.add_edge(category, offer)\n",
    "\n",
    "# Add bank transactions\n",
    "for tx in customer_data[\"related_bank_transactions\"]:\n",
    "    tx_id = tx[\"transaction_id\"]\n",
    "    tx_label = f\"Bank: {tx['type']} ${tx['amount']}\"\n",
    "    G.add_node(tx_id, label=tx_label, type=\"bank_tx\")\n",
    "    G.add_edge(customer_id, tx_id)\n",
    "\n",
    "# Draw graph\n",
    "plt.figure(figsize=(14, 12))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Assign colors based on node type\n",
    "node_colors = []\n",
    "for node, data in G.nodes(data=True):\n",
    "    if data[\"type\"] == \"customer\":\n",
    "        node_colors.append(\"skyblue\")\n",
    "    elif data[\"type\"] == \"bank_tx\":\n",
    "        node_colors.append(\"lightgreen\")\n",
    "    elif data[\"type\"] == \"credit_card_tx\":\n",
    "        node_colors.append(\"salmon\")\n",
    "    elif data[\"type\"] == \"merchant\":\n",
    "        node_colors.append(\"orange\")\n",
    "    elif data[\"type\"] == \"category\":\n",
    "        node_colors.append(\"violet\")\n",
    "    elif data[\"type\"] == \"offer\":\n",
    "        node_colors.append(\"gold\")\n",
    "    else:\n",
    "        node_colors.append(\"gray\")\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=600)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "\n",
    "# Draw labels\n",
    "labels = {node: data[\"label\"] for node, data in G.nodes(data=True)}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "\n",
    "plt.title(\"Extended Customer Transaction Graph\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e749fb9",
   "metadata": {},
   "source": [
    "## Customer Segmentation - Power BI-style dashboards using matplotlib and seaborn.\n",
    "### DocumentDB can be integrated to Power BI for generating such dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352f32e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from MongoDB collections\n",
    "customers_df = pd.DataFrame(list(db.customers.find()))\n",
    "bank_tx_df = pd.DataFrame(list(db.customer_bank_trans.find()))\n",
    "cc_tx_df = pd.DataFrame(list(db.customer_card_trans.find()))\n",
    "\n",
    "# Drop MongoDB internal _id field\n",
    "for df in [customers_df, bank_tx_df, cc_tx_df]:\n",
    "    df.drop(columns=[\"_id\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Combine bank and credit card transactions\n",
    "bank_tx_df[\"source\"] = \"bank\"\n",
    "cc_tx_df[\"source\"] = \"credit_card\"\n",
    "combined_tx_df = pd.concat([bank_tx_df, cc_tx_df], ignore_index=True)\n",
    "\n",
    "# Calculate total spending per customer\n",
    "spending_summary = combined_tx_df.groupby(\"customer_id\")[\"amount\"].sum().reset_index()\n",
    "spending_summary.rename(columns={\"amount\": \"total_spending\"}, inplace=True)\n",
    "\n",
    "# Merge with customer profiles\n",
    "customer_summary = pd.merge(customers_df, spending_summary, on=\"customer_id\", how=\"left\")\n",
    "customer_summary[\"total_spending\"].fillna(0, inplace=True)\n",
    "\n",
    "# Segment customers based on total spending\n",
    "def segment_customer(spending):\n",
    "    if spending < 500:\n",
    "        return \"Low\"\n",
    "    elif spending < 2000:\n",
    "        return \"Medium\"\n",
    "    elif spending < 5000:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Premium\"\n",
    "\n",
    "customer_summary[\"segment\"] = customer_summary[\"total_spending\"].apply(segment_customer)\n",
    "\n",
    "# Plot 1: Spending distribution by segment\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=\"segment\", y=\"total_spending\", data=customer_summary, order=[\"Low\", \"Medium\", \"High\", \"Premium\"])\n",
    "plt.title(\"Customer Spending Distribution by Segment\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Total Spending\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Count of customers by segment\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.countplot(x=\"segment\", data=customer_summary, order=[\"Low\", \"Medium\", \"High\", \"Premium\"], palette=\"Set2\")\n",
    "plt.title(\"Customer Count by Segment\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Total spending by transaction source\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(x=\"source\", y=\"amount\", data=combined_tx_df, estimator=sum, ci=None, palette=\"Set1\")\n",
    "plt.title(\"Total Spending by Transaction Source\")\n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Total Amount\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87879a7",
   "metadata": {},
   "source": [
    "## Implement Retrieval-Augmented Generation (RAG) using IVF, HNSW, DiskANN\n",
    "\n",
    "#### Azure DocumentDB provides robust vector search capabilities, allowing you to perform high-speed similarity searches across complex datasets. To perform vector search in Azure DocumentDB, you first need to create a vector index. While Azure DocumentDB offers multiple options, here are some general guidelines to help you get started based on the size of your dataset:\n",
    "\n",
    "[Integrated vector store in Azure DocumentDB](https://learn.microsoft.com/en-us/azure/documentdb/vector-search?tabs=hnsw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c4b13",
   "metadata": {},
   "source": [
    "### Imports + config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d22536",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from pymongo import MongoClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Step 1: Configure Azure OpenAI\n",
    "openai.api_type = config['OPENAI_API_TYPE']\n",
    "openai.api_base = config['OPENAI_API_ENDPOINT']\n",
    "openai.azure_endpoint = config['OPENAI_API_ENDPOINT']\n",
    "openai.api_version = config['OPENAI_API_VERSION']\n",
    "embedding_model = config['OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "\n",
    "azure_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(azure_credential,\n",
    "    \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    azure_endpoint=openai.azure_endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=openai.api_version,\n",
    ")\n",
    "\n",
    "# ---- Vector field settings ----\n",
    "vector_field = \"vectorEmbedding\"\n",
    "vector_dimensions = 1536\n",
    "rag_coll_name = \"customer_embeddings\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7267d1",
   "metadata": {},
   "source": [
    "### Connect to DocumentDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343db3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Connect to MongoDB\n",
    "client = MongoClient(connection_string)\n",
    "db = client[db_name]\n",
    "db[rag_coll_name].drop()\n",
    "rag_coll = db[rag_coll_name]\n",
    "\n",
    "\n",
    "# quick sanity check\n",
    "print(\"Connected. Collection:\", rag_coll.full_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ded2d",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9102f",
   "metadata": {},
   "source": [
    "#### Helper Function To Drop Any Previous Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061b98b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def drop_vector_indexes_on_field(collection, vector_field: str):\n",
    "    idx = list(collection.list_indexes())\n",
    "    to_drop = []\n",
    "    for i in idx:\n",
    "        # Cosmos vector indexes show up as key: { <field>: \"cosmosSearch\" }\n",
    "        keys = i.get(\"key\", {})\n",
    "        if keys.get(vector_field) == \"cosmosSearch\":\n",
    "            to_drop.append(i[\"name\"])\n",
    "    for name in to_drop:\n",
    "        print(\"Dropping index:\", name)\n",
    "        collection.drop_index(name)\n",
    "    return to_drop\n",
    "\n",
    "dropped = drop_vector_indexes_on_field(rag_coll, vector_field)\n",
    "print(\"Dropped:\", dropped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c630d",
   "metadata": {},
   "source": [
    "### Types of vector indexes supported in Azure DocumentDB: IVF, HNSW, DiskANN\n",
    "\n",
    "\n",
    "<style>\n",
    "  table, th, td {\n",
    "    font-size: 12px; /* Adjust the font size as needed */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "|  | IVF | HNSW | DiskANN |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Description | An IVFFlat index divides vectors into lists, then searches a subset closest to the query vector. | An HNSW index creates a multilayer graph. | DiskANN is an approximate nearest neighbor search algorithm designed for efficient vector search at any scale. |\n",
    "| Key trade-offs | Pros: Faster build times, lower memory use. Cons: Lower query performance (in terms of speed-recall tradeoff). | Pros: Better query performance (in terms of speed-recall tradeoff) can be created on an empty table. Cons: Slower build times, higher memory use. | Pros: Efficient at any scale, high recall, high throughput, low latency. |\n",
    "| Vector count | Under 10,000 | Up to 50,000 | Up to 500,000+ |\n",
    "| Recommended cluster tier | M10 or M20 | M30 and higher | M30 and higher |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f2194",
   "metadata": {},
   "source": [
    "#### Option 1: Helper Function To Create IVF Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b59f86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_ivf_index(collection, vector_field: str, dimensions: int, similarity=\"COS\", num_lists=10, index_name=None):\n",
    "    if index_name is None:\n",
    "        index_name = f\"ivf_index_{vector_field}\"\n",
    "\n",
    "    drop_vector_indexes_on_field(collection, vector_field)\n",
    "\n",
    "    index_command = {\n",
    "        \"createIndexes\": collection.name,\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": index_name,\n",
    "                \"key\": {vector_field: \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-ivf\",\n",
    "                    \"dimensions\": dimensions,\n",
    "                    \"similarity\": similarity,\n",
    "                    \"numLists\": num_lists,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    return collection.database.command(index_command)\n",
    "\n",
    "result = create_ivf_index(rag_coll, vector_field, vector_dimensions, similarity=\"COS\", num_lists=10)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463a788",
   "metadata": {},
   "source": [
    "#### Option 2: Helper Function To Create HNSW Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e8241",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_hnsw_index(collection, vector_field: str, dimensions: int, similarity=\"COS\",\n",
    "                      m=16, ef_construction=64, index_name=None):\n",
    "    if index_name is None:\n",
    "        index_name = f\"hnsw_index_{vector_field}\"\n",
    "\n",
    "    drop_vector_indexes_on_field(collection, vector_field)\n",
    "\n",
    "    index_command = {\n",
    "        \"createIndexes\": collection.name,\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": index_name,\n",
    "                \"key\": {vector_field: \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-hnsw\",\n",
    "                    \"dimensions\": dimensions,\n",
    "                    \"similarity\": similarity,\n",
    "                    \"m\": m,\n",
    "                    \"efConstruction\": ef_construction,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    return collection.database.command(index_command)\n",
    "\n",
    "result = create_hnsw_index(rag_coll, vector_field, vector_dimensions, similarity=\"COS\", m=16, ef_construction=64)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac172352",
   "metadata": {},
   "source": [
    "#### Option 3: Helper Function To Create DiskANN Vector Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3218d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_diskann_index(collection, vector_field: str, dimensions: int, similarity=\"COS\",\n",
    "                         max_degree=32, l_build=64, index_name=None):\n",
    "    if index_name is None:\n",
    "        index_name = f\"diskann_index_{vector_field}\"\n",
    "\n",
    "    drop_vector_indexes_on_field(collection, vector_field)\n",
    "\n",
    "    index_command = {\n",
    "        \"createIndexes\": collection.name,\n",
    "        \"indexes\": [\n",
    "            {\n",
    "                \"name\": index_name,\n",
    "                \"key\": {vector_field: \"cosmosSearch\"},\n",
    "                \"cosmosSearchOptions\": {\n",
    "                    \"kind\": \"vector-diskann\",\n",
    "                    \"dimensions\": dimensions,\n",
    "                    \"similarity\": similarity,\n",
    "                    \"maxDegree\": max_degree,\n",
    "                    \"lBuild\": l_build,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    return collection.database.command(index_command)\n",
    "\n",
    "result = create_diskann_index(rag_coll, vector_field, vector_dimensions, similarity=\"COS\", max_degree=32, l_build=64)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b46373",
   "metadata": {},
   "source": [
    "#### Helper Function To Perform Vector Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719723bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def vector_search(collection, vector_field: str, query_vector, k=5, pre_filter=None):\n",
    "    cosmos_search = {\n",
    "        \"path\": vector_field,\n",
    "        \"vector\": query_vector,\n",
    "        \"k\": k,\n",
    "    }\n",
    "    if pre_filter:\n",
    "        cosmos_search[\"filter\"] = pre_filter\n",
    "\n",
    "    pipeline = [{\"$search\": {\"cosmosSearch\": cosmos_search}}]\n",
    "    return list(collection.aggregate(pipeline))\n",
    "\n",
    "# Example query vector (replace with embedding output)\n",
    "# query_vector = [0.02] * DIMENSIONS\n",
    "# results = vector_search(col, VECTOR_FIELD, query_vector, k=3)\n",
    "\n",
    "# print(\"Results:\", len(results))\n",
    "# results[:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dc6bb",
   "metadata": {},
   "source": [
    "#### Read data from customer collections, create embeddings and insert to RAG collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c1e7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Read data from collections\n",
    "customer_profiles = list(db[\"customers\"].find().limit(10))\n",
    "\n",
    "# Step 4: Embed and store documents\n",
    "def embed_and_store(text, metadata):\n",
    "    response = azure_openai_client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=embedding_model\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    doc = {\n",
    "        \"text\": text,\n",
    "        vector_field: embedding,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    db[\"customer_embeddings\"].insert_one(doc)\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Process each customer and their transactions\n",
    "for customer in customer_profiles:\n",
    "    customer_id = customer.get(\"customer_id\")\n",
    "    print(\"Processing customer:\", customer_id)\n",
    "\n",
    "    # Embed customer profile\n",
    "    profile_text = (\n",
    "        f\"Customer ID: {customer.get('customer_id')}; \"\n",
    "        f\"Name: {customer.get('name')}; \"\n",
    "        f\"Email: {customer.get('email')}; \"\n",
    "        f\"Phone: {customer.get('phone')}; \"\n",
    "        f\"Address: {customer.get('address')}; \"\n",
    "        f\"Date of Birth: {customer.get('dob')}; \"\n",
    "        f\"Account Open Date: {customer.get('account_open_date')}\"\n",
    "    )\n",
    "    embed_and_store(profile_text, {\"type\": \"customer_profile\", \"customer_id\": customer_id})\n",
    "\n",
    "    # Embed bank transactions\n",
    "    bank_transactions = list(db[\"customer_bank_trans\"].find({\"customer_id\": customer_id}))\n",
    "    for txn in bank_transactions:\n",
    "        txn_text = (\n",
    "            f\"Bank Transaction ID: {txn.get('transaction_id')}; \"\n",
    "            f\"Customer ID: {txn.get('customer_id')}; \"\n",
    "            f\"Date: {txn.get('date')}; \"\n",
    "            f\"Type: {txn.get('type')}; \"\n",
    "            f\"Amount: {txn.get('amount')}; \"\n",
    "            f\"Description: {txn.get('description')}\"\n",
    "        )\n",
    "        embed_and_store(txn_text, {\"type\": \"bank_transaction\", \"customer_id\": customer_id})\n",
    "\n",
    "    # Embed credit card transactions\n",
    "    credit_card_transactions = list(db[\"customer_card_trans\"].find({\"customer_id\": customer_id}))\n",
    "    for cc_txn in credit_card_transactions:\n",
    "        cc_text = (\n",
    "            f\"Credit Card Transaction ID: {cc_txn.get('transaction_id')}; \"\n",
    "            f\"Customer ID: {cc_txn.get('customer_id')}; \"\n",
    "            f\"Date: {cc_txn.get('date')}; \"\n",
    "            f\"Merchant: {cc_txn.get('merchant')}; \"\n",
    "            f\"Category: {cc_txn.get('category')}; \"\n",
    "            f\"Amount: {cc_txn.get('amount')}; \"\n",
    "            f\"Description: {cc_txn.get('description')}\"\n",
    "        )\n",
    "        embed_and_store(cc_text, {\"type\": \"credit_card_transaction\", \"customer_id\": customer_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f85210",
   "metadata": {},
   "source": [
    "#### Perform Vector Search Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61744e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sample RAG queries\n",
    "# sample_queries = [\n",
    "#     \"Which customers have frequent withdrawals?\"\n",
    "# ]\n",
    "sample_queries = [\n",
    "    \"Which customers have frequent withdrawals?\",\n",
    "    \"Find customers with high-value transactions across both bank and credit card\",\n",
    "    \"Which customers have unusual transaction description?\",\n",
    "    \"Find credit card transactions in the groceries category.\",\n",
    "    \"Who are the customers with consistent spending patterns?\"\n",
    "]\n",
    "\n",
    "# Run queries\n",
    "for query in sample_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    query_embedding = azure_openai_client.embeddings.create(\n",
    "        input=[query],\n",
    "        model=embedding_model\n",
    "    ).data[0].embedding\n",
    "    results = vector_search(rag_coll, vector_field, query_embedding)\n",
    "    # print(\"Results:\", results)\n",
    "    for result in results:\n",
    "        print(f\"Score: {result['__cosmos_meta__']['score']:.4f} | Text: {result['text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
